<!DOCTYPE html>
<html>
  <head>
    <title>BayesComp Satellite Workshop on Bayesian Computation and Inference with Misspecified Models</title>
    
    <link rel="stylesheet" type="text/css" href="css/main.css">
  
  </head>

  <body>
    
        <nav>
<ul>
<!-- <li><a href="/">Home</a></li> -->
<!-- <li><a href="/registration">Registration</a></li> -->
<!-- <li><a href="/deadlines">Deadlines</a></li> -->
<!-- <li><a href="/submission">Submission</a></li> -->
<!-- <li><a href="/programme">Programme</a></li> -->
<!-- <li><a href="/award">Award</a></li> -->
<!-- <li><a href="/past">Past</a></li> -->
<!-- <li><a href="/accommodation">Accommodation</a></li> -->
<!-- <li><a href="/travel">Travel</a></li> -->
<!-- <li><a href="/organisation">Organisation</a></li> -->
</ul>
    </nav>
    

<!---
<div align="right">
<a href="mailto:steinworkshop@gmail.com">email</a>
</div>
--->

    
  <div class="container">

		<div class="blurb">
			<h1>Bayesian Computation and Inference with Misspecified Models <img src="images/BayesCompHeader.png" alt="BayesComp poster", width="460", height="183", align="right", style="padding:30px;"></h1>
			<h4>Satellite Workshop BayesComp 2025</h4>
			<p><strong>Date:</strong> 16-17 June 2025.</p> 
			<p><strong>Location:</strong> National University of Singapore.</p>
			
		</div> 

<div class="blurb">

	
<p>
This <a href="https://bayescomp2025.sg/">BayesComp 2025</a> Satellite Workshop is about methods, theory and applications for Bayesian inference with misspecified models.
</p>

<section>
  
<h4> Outline </h4>

<p>  
A common justification for the use of Bayesian inference is that Bayes’ theorem is the optimal way to update beliefs based on new observations, and that representing beliefs through a posterior distribution is desirable for uncertainty quantification. However, standard posterior distributions are only meaningful when the model or likelihood is well-specified, which is not the case in the presence of outliers, adversarial contaminations, or faulty measurement instruments. This realisation has led to an increased focus on generalisations of Bayesian inference which aim to produce ‘generalised posterior distributions’ that provide some representation of uncertainty but also overcome some of the lack of robustness of standard posteriors. The aim of this workshop will be to give a broad overview of this topic, touching on both foundational questions and algorithmic advances, and inviting the BayesComp community to take a more active role in solving some of the remaining open challenges in this area.
</p>

</div>

<div class="blurb">
  
<h4> Call for Poster Sessions Abstracts </h4>
<p> We would like to invite the submisison of abstracts for the poster session on the second afternoon. Abstracts can be submitted <a href="https://forms.gle/PtXz5YR5iLNiAULJ7">here</a> and should be limited to 200 words. The deadline for abstract submission is 1st May 2025. A selection of accepted posters will be given the oppourtunity to present their work in the spotlight session on Monday afternoon.
</p>
  
  
</div>


<div class="blurb">

<h3> Programme </h3>
<p>The tentative programme for this workshop is below. This programme is subject to change.
</p>

<p>Monday 16 June
<ul>
<li>09.00-10.30 Tutorial: Jeremias Knoblauch - post-Bayesian Inference</li>
<li>10.30-11.00 <b>Coffee</b></li>
<li>11.00-11.45 Invited Talk: Antonietta Mira </li>
<li>11.45-12.30 Invited Talk: Jeremie Houssineau - Robust Bayesian inference with possibility theory </li>
<li>12.30-14.00 <b>Lunch</b></li>
<li>14.00-15.30 Poster Spotlight Talks </li>
<li>15.30-16.00 <b>Coffee</b></li>
<li>16.00-17.00 Invited Talk: Sonia Petrone </li>
<li>17.00-18.00 Invited Talk: David Frazier </li>
</ul>
</p>

<p>Tuesday 17 June
<ul>
<li>09.00-09.45 Invited Talk: Eli Weinstein</li>
<li>09.45-10.30 Invited Talk: Aretha Teckentrup</li>
<li>10.30-11.00 <b>Coffee</b></li>
<li>11.00-11.45 Invited Talk: Edwin Fong - Model misspecification in martingale posteriors </li>
<li>11.45-12.30 Invited Talk: Harita Dellaporta - Model-based Distributionally Robust Optimisation: Bayesian Ambiguity Sets and Model Misspecification </li>
<li>12.30-14.00 <b>Lunch</b></li>
<li>14.00-15.30 Poster Session </li>
<li>15.30-16.00 <b>Coffee</b></li>
<li>16.00-17.00 Invited Talk: Pierre Alquier - A new mutual information bound for satistical inference</li>
<li>17.00-18.00 Invited Talk: TBC </li>
</ul>
</p>	
	
</div>

<div class="blurb">

	<h4> Speakers </h4>

	<ul>

		<li> <strong><a href="https://jeremiasknoblauch.github.io/"> Jeremias Knoblauch (University College London, UK).</a></strong> <br/> <br/>

			
			<strong> Title: </strong> Post-Bayesian Inference. <br/>

			<strong> Abstract: </strong> In this talk, I provide my perspective on our  community's efforts to develop inference procedures with Bayesian characteristics that go beyond Bayes' Rule as an epistemological principle.  I will explain why these efforts are needed, as well as the forms which they take. Focusing on some of my own contributions to the field, I will trace out some of the community's most important milestones, as well as the challenges that lie ahead. Throughout, I will provide success stories of the field, and emphasise the new opportunities that open themselves up to us once we dare to go beyond orthodox Bayesian procedures. <br/>
      <!---
			<a href="https://steinworkshop.github.io/slides/anima_anandkumar.pptx"><strong>[Slides]</strong></a><br/>
      --->
		</li>

		<li> <strong><a href="https://search.usi.ch/en/people/f8960de6d60dd08a79b6c1eb20b7442b/mira-antonietta"> Antonietta Mira (Università
della Svizzera italiana, Switzerland).</a></strong> <br/><br/>

			<!---
			<strong> Title: </strong>  <br/>

			<strong> Abstract: </strong>  <br/>
      --->
			

		</li>
		
		<li> <strong><a href="https://jeremiehoussineau.com/"> Jeremie Houssineau (Nanyang Technological University, Singapore).</a></strong> <br/><br/>

			
		
			<strong> Title: Robust Bayesian inference with possibility theory </strong>  <br/>

			<strong> Abstract: In Bayesian inference, the marginal likelihood is one of the main quantities for model selection based on its ability to capture the fitness of the model. Yet, when reformulating Bayesian inference in the context of possibility theory, the marginal likelihood no longer favours simpler models and cannot be used directly for model selection. What it can do however, is capture the coherence between the model and the observation(s). This possibilistic marginal likelihood therefore provides a simple solution to make the underlying inference more robust, leveraging useful properties that are specific to possibility theory. Illustrations will be given for multiple problems of varying difficulty, focusing on robustness to outliers.</strong>  <br/>


			

		</li>
		
		<li> <strong><a href="https://faculty.unibocconi.eu/soniapetrone/"> Sonia Petrone (Bocconi University, Italy).</a></strong> <br/><br/>

			
			<!---
			<strong> Title: </strong>  <br/>

			<strong> Abstract: </strong>  <br/>
      --->

			

		</li>
		
		<li> <strong><a href="https://dtfrazier.netlify.app/"> David Frazier (Monash University, Australia).</a></strong> <br/><br/>

			
			<!---
			<strong> Title: </strong>  <br/>

			<strong> Abstract: </strong>  <br/>
      --->

			

		</li>
		
		<li> <strong><a href="https://eweinstein.github.io/"> Eli Weinstein (Columbia University).</a></strong> <br/><br/>

			
			<!---
			<strong> Title: </strong>  <br/>

			<strong> Abstract: </strong>  <br/>
      --->

			

		</li>
		
		<li> <strong><a href="https://www.maths.ed.ac.uk/~ateckent/"> Aretha Teckentrup (University of Edinburgh, UK).</a></strong> <br/><br/>

			
			<!---
			<strong> Title: </strong>  <br/>

			<strong> Abstract: </strong>  <br/>
      --->

			

		</li>
		
		<li> <strong><a href="https://edfong.github.io/"> Edwin Fong (University of Hong Kong).</a></strong> <br/><br/>

			
			<strong> Title: </strong> Model misspecification in martingale posteriors <br/>

			<strong> Abstract: </strong> The martingale posterior is a framework where posterior uncertainty is directly generated through predictive imputation. The Bayesian model can then be directly specified using a sequence of predictive distributions, bypassing the need for explicit likelihood and prior specifications. Given the absence of a likelihood however, it is not immediately clear what the definition or impact of misspecification is for martingale posteriors. This talk will investigate predictive notions of misspecification, the consequences they have on parameter inference, and potential remedies. <br/>

			

		</li>
		
		<li> <strong><a href="https://haritadell.github.io/"> Harita Dellaporta (University College London, UK).</a></strong> <br/><br/>

			
			<strong> Title: </strong> Model-based Distributionally Robust Optimisation: Bayesian Ambiguity Sets and Model Misspecification.   <br/>

			<strong> Abstract: </strong> Decision making under uncertainty is challenging as the data-generating process (DGP) is often unknown. Bayesian inference proceeds by estimating the DGP through posterior beliefs about the model's parameters. However, minimising the expected risk under these posterior beliefs can lead to sub-optimal decisions due to model uncertainty or limited, noisy observations. This talk will address this problem by introducing Distributionally Robust Optimisation with Bayesian Ambiguity Sets (DRO-BAS) which hedges against model uncertainty by optimising the worst-case risk over a posterior-informed ambiguity set.  Simulations show DRO-BAS Pareto dominates existing Bayesian DRO formulations when evaluating the out-of-sample mean-variance trade-off, while achieving faster solve times. However, when the model is misspecified, this can lead to over-conservative decisions as the DGP might not be contained anymore in the ambiguity set. I will briefly discuss how Bayesian Ambiguity Sets can be easily adjusted to address this challenge by introducing DRO with Robust, to model misspecification, Bayesian Ambiguity Sets. These are expected Maximum Mean Discrepancy ambiguity sets under a robust posterior that incorporates beliefs about the DGP. The resulting optimisation problem obtains a dual formulation in the Reproducing Kernel Hilbert Space for any choice of model family.   <br/>

			

		</li>
		
		<li> <strong><a href="https://pierrealquier.github.io/"> Pierre Alquier (ESSEC Business School, Singapore).</a></strong> <br/><br/>

			
			<strong> Title: </strong> A new mutual information bound for satistical inference. <br/>

			<strong> Abstract: </strong> Recent advances in statistical learning theory have revealed profound connections between mutual information (MI) bounds, PAC-Bayesian theory, and Bayesian nonparametrics. This work introduces a novel mutual information bound for statistical inference. The derived bound has wide-ranging applications. It yields improved contraction rates for fractional posteriors in Bayesian nonparametrics. It can also be used to study variational inference or Maximum Likelihood Estimation (MLE). By bridging these diverse areas, this work advances our understanding of the fundamental limits of statist ical inference and the role of information in learning from data. We hope that these results will not only clarify connections between statistical inference and information theory but also help to develop a new toolbox to study a wide range of estimators. <br/>

			

		</li>

	</ul>

</div>



<div class="blurb">


<h4>Organisation</h4>


	<ul>
			<li> <strong><a href="https://fxbriol.github.io/"> François-Xavier Briol</a></strong>, UCL (f.briol@ucl.ac.uk) </li>

			<li> <strong><a href="https://sites.google.com/view/jack-jewson-academic-profile/home"> Jack Jewson</a></strong>, Monash University (jack.jewson@monash.edu)</li>

			<li> <strong><a href="https://jeremiasknoblauch.github.io/"> Jeremias Knoblauch</a></strong>, UCL (j.knoblauch@ucl.ac.uk)</li>
	</ul>


</div>

</div>

  <footer>
   <!-- <img src="https://steinworkshop.github.io/ati.jpg" alt="Ati Logo", width="255", height="115", align="center", style="padding:10px;"> -->
	<!-- Some logos here -->
  </footer>

</body>
</html>
